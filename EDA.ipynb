{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5fef32",
   "metadata": {},
   "source": [
    "- using https://database.itreetools.org/#/viableLocations for locations in California that has data in the system\n",
    "- collect html with https://ourtrees.itreetools.org/#/report? http get method web link\n",
    "- HTMLs are collect within Los Angeles County only.\n",
    "- Some data was wrongly input to database and can not find the right location.  It was deleted in LocationsList_2025-05-25.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nation', 'State', 'County', 'Place', 'Latitude', 'Longitude',\n",
      "       'Elevation (meters)'],\n",
      "      dtype='object')\n",
      "1682\n",
      "Nation                United States of America\n",
      "State                               California\n",
      "County                             Los Angeles\n",
      "Place                                 Pasadena\n",
      "Latitude                             34.176609\n",
      "Longitude                          -118.172614\n",
      "Elevation (meters)                  280.573425\n",
      "Name: 604, dtype: object\n",
      "                       Nation       State       County                Place  \\\n",
      "506  United States of America  California  Los Angeles                Acton   \n",
      "507  United States of America  California  Los Angeles         Agoura Hills   \n",
      "508  United States of America  California  Los Angeles  Agoura Hills-Malibu   \n",
      "509  United States of America  California  Los Angeles           Agua Dulce   \n",
      "510  United States of America  California  Los Angeles             Alhambra   \n",
      "\n",
      "      Latitude   Longitude  Elevation (meters)  \n",
      "506  34.472777 -118.183696          846.035400  \n",
      "507  34.153365 -118.761805          282.408356  \n",
      "508  34.153340 -118.761676                 NaN  \n",
      "509  34.504433 -118.316024         1268.000000  \n",
      "510  34.081859 -118.135052          137.256546  \n",
      "https://ourtrees.itreetools.org/#/report?longitude=-118.1726138&latitude=34.1766095&tab=benefits\n",
      "153\n",
      "html_files/CA_Antelope Valley.html\n",
      "https://ourtrees.itreetools.org/#/report?longitude=-118.2522977&latitude=34.7513712&tab=benefits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from lxml import html\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "if not os.path.exists('html_files'):\n",
    "    os.mkdir('html_files')\n",
    "\n",
    "locationList = pd.read_csv(\"data/LocationsList_2025-05-25.csv\")\n",
    "zipcode = pd.read_csv(\"data/zip_code_data.csv\")\n",
    "#print(zipcode.columns)\n",
    "print(locationList.columns)\n",
    "unique_values = locationList['Place'].unique()\n",
    "print(len(unique_values))\n",
    "pasadena = locationList[locationList['Place'] == 'Pasadena']\n",
    "print(pasadena.iloc[0])\n",
    "cityInCounty = locationList[locationList['County'] == 'Los Angeles']\n",
    "cityInCounty = cityInCounty.drop_duplicates(subset='Place', keep='first')\n",
    "print(cityInCounty.head(5))\n",
    "\n",
    "filename = f'html_files/CA_pasadena.html'\n",
    "Longitude = pasadena.iloc[0]['Longitude']\n",
    "Latitude = pasadena.iloc[0]['Latitude']\n",
    "url = f'https://ourtrees.itreetools.org/#/report?longitude={Longitude}&latitude={Latitude}&tab=benefits'\n",
    "print(url)\n",
    "# Make a GET request to the URL and save the response content to a file\n",
    "options = Options()\n",
    "options.add_argument(\"headless\")  # Don't show browser window\n",
    "\n",
    "\n",
    "accuTime = 0\n",
    "print(len(cityInCounty))\n",
    "for index, row in cityInCounty.iterrows():\n",
    "    filename = \"html_files/CA_\" + row['Place'] + \".html\"\n",
    "\n",
    "    genHTML = True\n",
    "    if os.path.exists(filename) :\n",
    "        if (os.path.getsize(filename)/ 1024) > 50:\n",
    "            genHTML = False\n",
    "    \n",
    "    if genHTML:\n",
    "        print(filename)\n",
    "        \n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        url = \"https://ourtrees.itreetools.org/#/report?longitude=\"+ str(row['Longitude']) + \"&latitude=\" + str(row['Latitude']) + \"&tab=benefits\"\n",
    "        \n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        # wait for the page to finish rendering\n",
    "        time.sleep(30)  # or use WebDriverWait with specific DOM condition\n",
    "        html = driver.page_source\n",
    "        accuTime = 0\n",
    "        while 'Estimating' in html:\n",
    "            time.sleep(3)\n",
    "            html = driver.page_source\n",
    "            accuTime = accuTime + 3\n",
    "            if accuTime > 480:\n",
    "                break\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(html)\n",
    "        #print(html)\n",
    "        driver.quit()\n",
    "        time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd9ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_files/CA_pasadena.html\n",
      "['13.19%', 'tree', 'canopy', 'on', '1,939', 'acres']\n",
      "['38.08%', 'impervious', 'surfaces', 'over', '5,598', 'acres']\n",
      "City: CA_pasadena\n",
      "Total i-Tree benefits($): 3039197\n",
      "Carbon Dioxide Uptake($): 1498517\n",
      "Carbon Sequestered(tn): 3463\n",
      "CO2 Equivalent1(tn): 12698\n",
      "Storm Water Mitigation($): 256108\n",
      "Runoff Avoided(MG/yr): 29\n",
      "Rainfall Intercepted(MG/yr): 76\n",
      "Air Pollution Removal($): 1284572\n",
      "Carbon Monoxide(lb/yr): 4563\n",
      "Ozone(lb/yr): 162164\n",
      "Nitrogen Dioxide(lb/yr): 29180\n",
      "Sulfur Dioxide(lb/yr): 5879\n",
      "PM2.5(lb/yr): 2450\n",
      "Carbon Dioxide Uptake($)-2: 29785452\n",
      "Carbon Storage(tn): 68832\n",
      "CO2 Equivalent1(tn)-2: 252384\n",
      "percent canopy: 13.19\n",
      "Total Land(acres): 1939\n",
      "percent impervious: 38.08\n",
      "impervious(acres): 5598\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "from pyquery import PyQuery\n",
    "import re\n",
    "\n",
    "def getDictItem(pairs, keys):\n",
    "    if len(pairs) > 1:\n",
    "        col = items(pairs[0]).text().replace(\":\", \"\")\n",
    "        colstr = col.split(\" \")\n",
    "        if len(colstr) > 3:\n",
    "            col = \" \".join([colstr[0], colstr[1], colstr[2]])\n",
    "        \n",
    "        value = items(pairs[1]).text()\n",
    "        if len(value.split(\" \")) > 1:\n",
    "            col = col + \"(\" + value.split(\" \")[1] + \")\"\n",
    "            value = value.split(\" \")[0]\n",
    "        if \"$\" in value:\n",
    "            col = col + \"($)\"\n",
    "\n",
    "        value = re.sub(r\"[$,]\", \"\", value)\n",
    "\n",
    "        if col in keys:\n",
    "            col = col + \"-2\"\n",
    "        return {col: value}\n",
    "    return {}\n",
    "    \n",
    "with open(filename, 'r',encoding='ISO-8859-1') as f:\n",
    "    html_str = f.read()\n",
    "    doc = PyQuery(html_str)\n",
    "    print(filename)\n",
    "    row = {\"City\": re.split(r\"[./]\", filename)[1]}\n",
    "    # parse benefits page\n",
    "    labels = [ \"City\", \"percent canopy\", \"Total Land(acres)\", \"percent impervious\", \"impervious(acres)\", \"Total i-Tree benefits($)\", \"Carbon Dioxide Uptake($)\", \"Carbon Sequestered(tn)\",\n",
    "              \"CO2 Equivalent1(tn)\", \"Storm Water Mitigation($)\", \"Runoff Avoided(MG/yr)\", \"Rainfall Intercepted(MG/yr)\", \"Air Pollution Removal($)\",\n",
    "              \"Carbon Monoxide(lb/yr)\", \"Ozone(lb/yr)\", \"Nitrogen Dioxide(lb/yr)\", \"Sulfur Dioxide(lb/yr)\", \"PM2.5(lb/yr)\", \"Carbon Dioxide Uptake-2($)\", \"Carbon Storage(tn)\", \"CO2 Equivalent1-2(tn)\"]\n",
    "    \n",
    "    benefits = doc(\"#benefits\")\n",
    "    items = benefits(\".justify-content-between\")\n",
    "    for i, item in enumerate(items.items(), 1):\n",
    "        strong = item.find(\"strong\")\n",
    "        row = row | getDictItem(strong, row.keys())\n",
    "        p = item.find(\"p\")\n",
    "        row = row | getDictItem(p, row.keys())\n",
    "\n",
    "    topitem = benefits(\".my-0\")\n",
    "    toplist1 = items(topitem[0]).text().split(\" \")\n",
    "    toplist2 = items(topitem[1]).text().split(\" \")\n",
    "    print(toplist1)\n",
    "    print(toplist2)\n",
    "    row[\"percent canopy\"] = re.sub(r\"[%]\", \"\", toplist1[0])\n",
    "    row[\"Total Land(acres)\"] = re.sub(r\",\", \"\", toplist1[4])\n",
    "    row[\"percent impervious\"] = re.sub(r\"[%]\", \"\", toplist2[0])\n",
    "    row[\"impervious(acres)\"] = re.sub(r\",\", \"\", toplist2[4])\n",
    "\n",
    "    for key, value in row.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(len(row.keys()))\n",
    "\n",
    "    Community = doc(\"#Community\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cee57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 'deepforest' from file 'deep_forest_init.geojson' (treeType=box) ...\n",
      "Finished processing model 'deepforest'.\n",
      "Processing model 'deepforest10cm' from file 'pasadena_predictions_4326_10cm.geojson' (treeType=box) ...\n",
      "Finished processing model 'deepforest10cm'.\n",
      "Processing model 'cv60cm' from file 'merged_pasadena_60cm_cv.json' (treeType=pt) ...\n"
     ]
    },
    {
     "ename": "DataSourceError",
     "evalue": "./greencityEc2/geojson/merged_pasadena_60cm_cv.json: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(js_filename):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m model_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileMerge\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreePoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreeType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m js_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Optionally add processed geojson for map use\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# js_variable_name = \"census_blocks_\" + treePoints[index]\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# js_lines.append(f\"window.{js_variable_name} = {json.dumps(model_data['features'])};\")\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Add tree GeoJSON\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mprocess_model\u001b[1;34m(file, model, tree_type, blocks)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_model\u001b[39m(file, model, tree_type, blocks):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m from file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (treeType=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtree_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     trees \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeojson_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Ensure CRS matches\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trees\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m!=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mcrs:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\geopandas\\io\\file.py:317\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m             filename \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\geopandas\\io\\file.py:577\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    574\u001b[0m     )\n\u001b[0;32m    575\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyogrio\\geopandas.py:275\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1293\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:232\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: ./greencityEc2/geojson/merged_pasadena_60cm_cv.json: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "\n",
    "fileMerge = [\n",
    "    \"Street_ROW_Trees.geojson\", \n",
    "    \"merged_pasadena_2048_0.6m_baseline.geojson\",\n",
    "    \"deep_forest_init.geojson\", \n",
    "    \"pasadena_predictions_4326_10cm.geojson\",\n",
    "    \"merged_pasadena_60cm_cv.geojson\",\n",
    "    \"pasadena_merged_polygons_4326.geojson\"\n",
    "]\n",
    "\n",
    "treePoints = [\"training\", \"baseline\", \"deepforest\", \"deepforest10cm\", \"cv60cm\", \"deepforest10cmMerged\"]\n",
    "treeType = [\"pt\", \"pt\", \"box\", \"box\", \"pt\", \"box\"]\n",
    "\n",
    "geojson_dir = \"./greencityEc2/geojson/\"  # Adjust if your files are stored elsewhere\n",
    "\n",
    "blocks = gpd.read_file(os.path.join(geojson_dir, \"2010_Census_Blocks.geojson\"))\n",
    "\n",
    "projected_crs = \"EPSG:3857\"\n",
    "\n",
    "def process_model(file, model, tree_type, blocks):\n",
    "    print(f\"Processing model '{model}' from file '{file}' (treeType={tree_type}) ...\")\n",
    "\n",
    "    trees = gpd.read_file(os.path.join(geojson_dir, file))\n",
    "\n",
    "    # Ensure CRS matches\n",
    "    if trees.crs != blocks.crs:\n",
    "        trees = trees.to_crs(blocks.crs)\n",
    "\n",
    "    # Project both to meters\n",
    "    blocks_proj = blocks.to_crs(projected_crs)\n",
    "    trees_proj = trees.to_crs(projected_crs)\n",
    "\n",
    "    blocks_proj[\"areaSqM\"] = blocks_proj.geometry.area\n",
    "\n",
    "    if tree_type == \"pt\":\n",
    "        joined = gpd.sjoin(trees_proj, blocks_proj, how=\"inner\", predicate=\"within\")\n",
    "    elif tree_type == \"box\":\n",
    "        trees_proj[\"center\"] = trees_proj.geometry.centroid\n",
    "        rect_centers = trees_proj.copy()\n",
    "        rect_centers.set_geometry(\"center\", inplace=True)\n",
    "        joined = gpd.sjoin(rect_centers, blocks_proj, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "    joined_latlon = joined.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    tree_counts = joined.groupby(\"index_right\").size().rename(\"treeCount\")\n",
    "    blocks_proj[\"treeCount\"] = blocks_proj.index.map(tree_counts).fillna(0).astype(int)\n",
    "    blocks_proj[\"density\"] = (blocks_proj[\"treeCount\"] / blocks_proj[\"areaSqM\"]) * 10000\n",
    "\n",
    "    density_dict = dict(zip(blocks_proj[\"OBJECTID\"], blocks_proj[\"density\"]))\n",
    "\n",
    "    if tree_type == \"pt\":\n",
    "        tree_coords = joined_latlon.groupby(\"index_right\")[\"geometry\"].apply(\n",
    "            lambda pts: [pt.coords[0] for pt in pts if pt.geom_type == \"Point\"]\n",
    "        )\n",
    "    elif tree_type == \"box\":\n",
    "        tree_coords = joined_latlon.groupby(\"index_right\")[\"center\"].apply(\n",
    "            lambda pts: [pt.coords[0] for pt in pts]\n",
    "        )\n",
    "\n",
    "    geojson_dict = json.loads(trees.to_json())\n",
    "    features = geojson_dict.get(\"features\", [])\n",
    "\n",
    "    print(f\"Finished processing model '{model}'.\")\n",
    "    return {\n",
    "        \"density\": density_dict,\n",
    "        \"features\": features,\n",
    "        \"coords\": tree_coords.to_dict() if tree_coords is not None else {}\n",
    "    }\n",
    "\n",
    "# Loop over all files and process\n",
    "for index in range(len(fileMerge)):\n",
    "    js_filename = f\"{treePoints[index]}.js\"\n",
    "    if os.path.exists(js_filename):\n",
    "        continue\n",
    "\n",
    "    model_data = process_model(fileMerge[index], treePoints[index], treeType[index], blocks)\n",
    "\n",
    "    js_lines = []\n",
    "\n",
    "    # Optionally add processed geojson for map use\n",
    "    # js_variable_name = \"census_blocks_\" + treePoints[index]\n",
    "    # js_lines.append(f\"window.{js_variable_name} = {json.dumps(model_data['features'])};\")\n",
    "\n",
    "    # Add tree GeoJSON\n",
    "    trees = gpd.read_file(os.path.join(geojson_dir, fileMerge[index]))\n",
    "    trees_json = json.loads(trees.to_json())\n",
    "    js_lines.append(f\"window.{treePoints[index]} = {json.dumps(trees_json)};\")\n",
    "\n",
    "    # Write JavaScript file\n",
    "    full_js_content = \"\\n\\n\".join(js_lines)\n",
    "    with open(js_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_js_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
